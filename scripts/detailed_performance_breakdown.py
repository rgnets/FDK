#!/usr/bin/env python3
"""
Detailed Performance Breakdown
Analyzes exactly what takes time in the current implementation
"""

import time
import json
import requests
from typing import Dict, List, Any, Union
from datetime import datetime
import concurrent.futures

# Configuration
API_URL = "https://vgw1-01.dal-interurban.mdu.attwifi.com"
API_KEY = "xWCH1KHxwjHRZtNbyBDTrGQw1gDry98ChcXM7bpLbKaTUHZzUUBsCb77SHrJNHUKGLAKgmykxsxsAg6r"

def format_time(ms: float) -> str:
    """Format time in appropriate units"""
    if ms < 1000:
        return f"{ms:.0f}ms"
    else:
        return f"{ms/1000:.1f}s"

def analyze_current_implementation():
    """Analyze the current app's implementation"""
    print("="*80)
    print("CURRENT APP IMPLEMENTATION ANALYSIS")
    print("="*80)
    
    headers = {
        'Authorization': f'Bearer {API_KEY}',
        'Accept': 'application/json'
    }
    
    print("\nüìä Current App Flow (from DeviceRemoteDataSourceImpl):")
    print("   1. Fetch rooms (page_size=0)")
    print("   2. Fetch access_points (page_size=0)")  
    print("   3. Fetch switches (page_size=0)")
    print("   4. Fetch media_converters (page_size=0)")
    print("   5. Fetch wlan_devices (page_size=0)")
    print("   All fetched in PARALLEL using Future.wait()")
    
    # Simulate the actual app implementation
    print("\n‚è±Ô∏è Timing Each Endpoint:")
    print("-" * 50)
    
    total_start = time.perf_counter()
    
    # Track each endpoint
    endpoints = [
        ('rooms', '/api/pms_rooms.json?page_size=0'),
        ('access_points', '/api/access_points.json?page_size=0'),
        ('switches', '/api/switch_devices.json?page_size=0'),
        ('media_converters', '/api/media_converters.json?page_size=0'),
        ('wlan_devices', '/api/wlan_devices.json?page_size=0')
    ]
    
    results = {}
    timings = {}
    
    # Execute in parallel like the app does
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        futures = {}
        
        for name, endpoint in endpoints:
            def fetch(endpoint_url=endpoint):
                start = time.perf_counter()
                try:
                    response = requests.get(f"{API_URL}{endpoint_url}", 
                                          headers=headers, 
                                          timeout=60)
                    data = response.json()
                    elapsed = (time.perf_counter() - start) * 1000
                    
                    # Normalize response
                    if isinstance(data, list):
                        return {'data': data, 'count': len(data), 'time': elapsed}
                    elif isinstance(data, dict) and 'results' in data:
                        return {'data': data['results'], 'count': len(data['results']), 'time': elapsed}
                    else:
                        return {'data': [], 'count': 0, 'time': elapsed}
                except Exception as e:
                    elapsed = (time.perf_counter() - start) * 1000
                    return {'error': str(e), 'time': elapsed}
            
            futures[name] = executor.submit(fetch)
        
        # Collect results
        for name, future in futures.items():
            result = future.result()
            results[name] = result
            timings[name] = result['time']
            
            if 'error' in result:
                print(f"   {name:20s}: ERROR - {result['error'][:40]}")
            else:
                print(f"   {name:20s}: {format_time(result['time']):>8s} - {result['count']:4d} items")
    
    total_elapsed = (time.perf_counter() - total_start) * 1000
    
    print("-" * 50)
    print(f"   TOTAL PARALLEL TIME: {format_time(total_elapsed)}")
    
    # Analyze the bottleneck
    print("\nüîç Bottleneck Analysis:")
    slowest = max(timings.items(), key=lambda x: x[1])
    print(f"   Slowest endpoint: {slowest[0]} ({format_time(slowest[1])})")
    print(f"   This endpoint determines total time in parallel execution")
    
    # Calculate data volume
    print("\nüì¶ Data Volume Analysis:")
    total_items = sum(r.get('count', 0) for r in results.values())
    print(f"   Total items fetched: {total_items}")
    
    # Show what rooms already contain
    if 'rooms' in results and not results['rooms'].get('error'):
        rooms_data = results['rooms']['data']
        devices_in_rooms = 0
        
        for room in rooms_data:
            if isinstance(room, dict):
                devices_in_rooms += len(room.get('access_points', []))
                devices_in_rooms += len(room.get('media_converters', []))
        
        print(f"   Devices already in rooms: {devices_in_rooms}")
        
        if devices_in_rooms > 0:
            separate_devices = results.get('access_points', {}).get('count', 0) + \
                             results.get('media_converters', {}).get('count', 0)
            print(f"   Devices fetched separately: {separate_devices}")
            print(f"   ‚ö†Ô∏è REDUNDANCY: Fetching {separate_devices} devices that might already be in rooms!")
    
    return total_elapsed, results

def test_optimized_approach():
    """Test an optimized approach using only necessary data"""
    print("\n" + "="*80)
    print("OPTIMIZED APPROACH TEST")
    print("="*80)
    
    headers = {
        'Authorization': f'Bearer {API_KEY}',
        'Accept': 'application/json'
    }
    
    print("\nüìä Optimized Flow:")
    print("   1. Fetch rooms with embedded devices (page_size=0)")
    print("   2. Extract all device data from rooms")
    print("   3. Skip separate device endpoints")
    
    print("\n‚è±Ô∏è Timing Optimized Approach:")
    print("-" * 50)
    
    # Fetch only rooms
    start = time.perf_counter()
    
    response = requests.get(f"{API_URL}/api/pms_rooms.json?page_size=0", 
                           headers=headers, 
                           timeout=60)
    rooms_data = response.json()
    
    fetch_time = (time.perf_counter() - start) * 1000
    
    # Process the data
    start_process = time.perf_counter()
    
    if isinstance(rooms_data, list):
        rooms = rooms_data
    elif isinstance(rooms_data, dict):
        rooms = rooms_data.get('results', [])
    else:
        rooms = []
    
    devices = []
    for room in rooms:
        if isinstance(room, dict):
            room_name = room.get('name') or room.get('room')
            
            # Extract access points
            for ap in room.get('access_points', []):
                if isinstance(ap, dict):
                    devices.append({
                        'id': f"ap_{ap.get('id')}",
                        'name': ap.get('name'),
                        'type': 'access_point',
                        'location': room_name
                    })
            
            # Extract media converters
            for mc in room.get('media_converters', []):
                if isinstance(mc, dict):
                    devices.append({
                        'id': f"mc_{mc.get('id')}",
                        'name': mc.get('name'),
                        'type': 'media_converter',
                        'location': room_name
                    })
    
    process_time = (time.perf_counter() - start_process) * 1000
    total_time = fetch_time + process_time
    
    print(f"   Fetch rooms:     {format_time(fetch_time):>8s} - {len(rooms):4d} rooms")
    print(f"   Process devices: {format_time(process_time):>8s} - {len(devices):4d} devices")
    print("-" * 50)
    print(f"   TOTAL TIME:      {format_time(total_time):>8s}")
    
    return total_time, len(devices)

def calculate_savings():
    """Calculate potential time savings"""
    print("\n" + "="*80)
    print("PERFORMANCE COMPARISON")
    print("="*80)
    
    # Run both approaches
    current_time, current_results = analyze_current_implementation()
    optimized_time, device_count = test_optimized_approach()
    
    # Calculate savings
    time_saved = current_time - optimized_time
    improvement = (time_saved / current_time) * 100 if current_time > 0 else 0
    
    print("\n" + "="*80)
    print("RESULTS SUMMARY")
    print("="*80)
    
    print(f"\n‚è±Ô∏è Performance:")
    print(f"   Current implementation:  {format_time(current_time):>8s}")
    print(f"   Optimized approach:      {format_time(optimized_time):>8s}")
    print(f"   Time saved:              {format_time(time_saved):>8s}")
    print(f"   Improvement:             {improvement:>7.1f}%")
    
    print(f"\nüöÄ Optimization Impact:")
    if improvement > 80:
        print(f"   MASSIVE improvement - {improvement:.0f}% faster!")
        print("   Users would see data almost instantly")
    elif improvement > 50:
        print(f"   SIGNIFICANT improvement - {improvement:.0f}% faster!")
        print("   User experience would be noticeably better")
    elif improvement > 20:
        print(f"   GOOD improvement - {improvement:.0f}% faster!")
        print("   Worth implementing")
    else:
        print(f"   MODEST improvement - {improvement:.0f}% faster")
        print("   Consider if worth the effort")
    
    print(f"\nüí° Key Insight:")
    print(f"   The access_points endpoint is the bottleneck (~17 seconds)")
    print(f"   By using room-embedded devices, we skip this entirely!")
    print(f"   Result: {format_time(current_time)} ‚Üí {format_time(optimized_time)}")

def main():
    print("="*80)
    print("DETAILED PERFORMANCE BREAKDOWN")
    print(f"Timestamp: {datetime.now().isoformat()}")
    print(f"API URL: {API_URL}")
    print("="*80)
    
    calculate_savings()
    
    print("\n" + "="*80)
    print("RECOMMENDATIONS FOR CLEAN ARCHITECTURE")
    print("="*80)
    
    print("\n1Ô∏è‚É£ IMMEDIATE FIX (No Architecture Changes):")
    print("   ‚Ä¢ Modify DeviceRemoteDataSourceImpl._fetchDevicesFromEndpoint()")
    print("   ‚Ä¢ For 'access_points' type, extract from rooms instead")
    print("   ‚Ä¢ Keep other endpoints as fallback")
    
    print("\n2Ô∏è‚É£ REPOSITORY PATTERN ENHANCEMENT:")
    print("   ‚Ä¢ Add caching layer in DeviceRepositoryImpl")
    print("   ‚Ä¢ Cache key: environment + timestamp")
    print("   ‚Ä¢ TTL: 5 minutes (configurable)")
    
    print("\n3Ô∏è‚É£ USE CASE OPTIMIZATION:")
    print("   ‚Ä¢ Create GetDevicesWithCaching use case")
    print("   ‚Ä¢ Implements business logic for cache invalidation")
    print("   ‚Ä¢ Returns cached data if fresh")
    
    print("\n4Ô∏è‚É£ VIEWMODEL STATE MANAGEMENT (MVVM):")
    print("   ‚Ä¢ Use AsyncValue.loading() immediately")
    print("   ‚Ä¢ Show cached data while refreshing")
    print("   ‚Ä¢ Progressive updates as data arrives")
    
    print("\n5Ô∏è‚É£ CLEAN ARCHITECTURE COMPLIANCE:")
    print("   ‚úÖ All changes stay within their layers")
    print("   ‚úÖ No domain layer modifications needed")
    print("   ‚úÖ Dependency injection unchanged")
    print("   ‚úÖ Riverpod providers handle state")

if __name__ == "__main__":
    main()